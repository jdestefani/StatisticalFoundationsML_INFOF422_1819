{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-F-422 -  Statistical Foundations of Machine Learning \n",
    "\n",
    "### Jacopo De Stefani - __[Jacopo.De.Stefani@ulb.ac.be](mailto:Jacopo.De.Stefani@ulb.ac.be)__\n",
    "### Bertrand Lebichot - __[Bertrand.Lebichot@ulb.ac.be](mailto:Bertrand.Lebichot@ulb.ac.be)__\n",
    "### Arnaud Pollaris - __[Arnaud.Pollaris@ulb.ac.be](mailto:Arnaud.Pollaris@ulb.ac.be)__\n",
    "\n",
    "## TP 6 -  Ensembles of models and feature selection\n",
    "\n",
    "####  April 30, 2019\n",
    "\n",
    "#### Materials originally developed by *Yann-AÃ«l Le Borgne, Fabrizio Carcillo and Gianluca Bontempi*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Ensembles of models and feature selection are two machine learning techniques which can be used to improve the accuracy of preditions. \n",
    "\n",
    "Ensembles of models consist in building several predictive models using resampled subsets of the original training set. The method works particularly well for predictive models with high variance (for example, decision trees or neural networks). The average prediction of the resulting models usually strongly decreases the variance component of the error, and as a consequence improves the prediction accuracy. \n",
    "\n",
    "Feature selection aims at reducing the dimensionality of the problem, and is useful when input variables contain redundant or irrelevant (noisy) information. Benefits are twofold: it decreases the training time by simplifying the problem, and it decreases the complexity of the predictive model. This in turn usually improves the prediction accuracy, since high-dimensionality makes predictive models more prone to overfitting, and estimates of parameters more variant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will illustrate both techniques using the IMDB 5000 dataset, which contains 27 variables describing 5043 movies. The variables contain information about the director, actors, number of Facebook likes for each actor, duration, genre, language, country, etc... We will use them to predict the movie success (through the IMDB score). The dataset together with a description of the variables is at https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset.\n",
    "\n",
    "The dataset is on the github of the course, in datasets/movie_metadata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load and select a random subset of 1000 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data<-read.csv(\"movie_metadata.csv\")\n",
    "set.seed(2)\n",
    "data<-data[sample(nrow(data),1000),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.matrix.max.cols=50)\n",
    "data[1:2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is a mix of categorical and numerical variables, and some missing values. In order to simplify the analysis, let us remove the categorical variables, and replace the NA values with the mean values of the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the type of input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sapply(data[1,],class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices of categorical (factor) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_variables<-which(sapply(data[1,],class)==\"factor\")\n",
    "factor_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed<-data[,-factor_variables]\n",
    "summary(data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace NA values with mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_na_with_mean_value<-function(vec) {\n",
    "    mean_vec<-mean(vec,na.rm=T)\n",
    "    vec[is.na(vec)]<-mean_vec\n",
    "    vec\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed<-data.frame(apply(data_preprocessed,2,replace_na_with_mean_value))\n",
    "summary(data_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output variable (Y) is the `imdb_score`, and all other variables (X) are considered as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(3)\n",
    "\n",
    "X<-data_preprocessed[,setdiff(colnames(data_preprocessed),\"imdb_score\")]\n",
    "Y<-data_preprocessed[,\"imdb_score\"]\n",
    "\n",
    "N<-nrow(X)    #Number of examples\n",
    "n<-ncol(X)    #Number of input variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of the `imdb_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Modelling with linear and decision tree models\n",
    "\n",
    "#### Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let us create a linear model for predicting the IMDB score on the basis of the other variables, and compute its empricial mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS<-cbind(X,imdb_score=Y)\n",
    "    \n",
    "model<- ### Fill with your code here\n",
    "        \n",
    "Y.hat<- predict(model,X)\n",
    "        \n",
    "empirical_error<- ### Fill with your code here\n",
    "\n",
    "print(paste(\"Empirical error=\",round(empirical_error,digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which input variables are statistically correlated with the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the validation error with a 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-numeric(10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "     i.ts<-  ### Complete the code. i.ts should be the indices of the tessefor the i-th fold\n",
    "     X.ts<-X[i.ts,]  \n",
    "     Y.ts<-Y[i.ts]  \n",
    "     \n",
    "     i.tr<-  ### Complete the code. i.tr should be the indices of the training sefor the i-th fold\n",
    "     X.tr<-X[i.tr,]\n",
    "     Y.tr<-Y[i.tr]                          \n",
    "     \n",
    "     DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "    \n",
    "     model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "     Y.hat.ts<- predict(model,X.ts)\n",
    "        \n",
    "     CV.err[i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "}\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV.err),digits=4), \" ; std dev=\",round(sd(CV.err),digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modify the previous code to compute the empirical error using a decision tree model. Use the rpart package (see `?rpart` for help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(rpart)       ### Run install.packages(\"rpart\") to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS<-cbind(X,imdb_score=Y)\n",
    "\n",
    "model<- ### Fill with you code here\n",
    "        \n",
    "Y.hat<- predict(model,X)\n",
    "        \n",
    "empirical_error<-mean((Y.hat-Y)^2) \n",
    "\n",
    "print(paste(\"Empirical error=\",round(empirical_error,digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the resulting tree using the `prp` function from the library `rpart.plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(rpart.plot)  ### Run install.packages(\"rpart.plot\") to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prp(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the 10-fold cross-validation error using a decision tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-numeric(10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "     i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "     X.ts<-X[i.ts,]  \n",
    "     Y.ts<-Y[i.ts]  \n",
    "     \n",
    "     i.tr<-setdiff(1:N,i.ts)                \n",
    "     X.tr<-X[i.tr,]\n",
    "     Y.tr<-Y[i.tr]                          \n",
    "     \n",
    "     DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "    \n",
    "     model<- rpart(imdb_score~.,DS)\n",
    "        \n",
    "     Y.hat.ts<- predict(model,X.ts)\n",
    "        \n",
    "     CV.err[i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "    \n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV.err),digits=4), \" ; std dev=\",round(sd(CV.err),digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Ensemble of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now create an ensemble of R linear models to make predictions. Complete the code below so that\n",
    "\n",
    "* The training set is resampled before building a model\n",
    "* The predictions of all model are averaged before testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "R<-20\n",
    "\n",
    "CV.err<-numeric(10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "     i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "     X.ts<-X[i.ts,]  \n",
    "     Y.ts<-Y[i.ts]  \n",
    "     \n",
    "     \n",
    "     i.tr<-setdiff(1:N,i.ts)                \n",
    "    \n",
    "     Y.hat.ts.R<-matrix(0,nrow=nrow(X.ts),ncol=R)\n",
    "    \n",
    "     for (r in 1:R) {\n",
    "         i.tr.resample<-    ### Complete code: Resample training set with replacement\n",
    "         X.tr<-X[i.tr.resample,]\n",
    "         Y.tr<-Y[i.tr.resample]                          \n",
    "     \n",
    "         DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "    \n",
    "         model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "         Y.hat.ts.R[,r]<- predict(model,X.ts)\n",
    "     \n",
    "     }\n",
    "    \n",
    "     Y.hat.ts<-apply(Y.hat.ts.R,1,mean)\n",
    "     CV.err[i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "     }\n",
    "\n",
    "print(paste(\"CV error=\",round(mean(CV.err),digits=4), \" ; std dev=\",round(sd(CV.err),digits=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is the CV error lower than with a single linear model?\n",
    "* Use a decision tree as the base model. Is the CV error lower?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Feature selection\n",
    "\n",
    "Two are the main approaches to feature selection:\n",
    "\n",
    "\n",
    "* **Filter methods:** they are preprocessing methods. They attempt to\n",
    "assess the merits of features from the data, ignoring the effects of\n",
    "the selected feature subset on the performance of the learning\n",
    "algorithm. Examples are methods that select variables by ranking them\n",
    "through compression techniques (like PCA), or by computing correlation or a more advanced similarity measure such as minimum redundancy maximum relevance (mRMR) with the output.\n",
    "\n",
    "*  **Wrapper methods:** these methods assess subsets of variables\n",
    "according to their usefulness to a given predictor. The method\n",
    "conducts a search for a good subset using the learning algorithm\n",
    "itself as part of the evaluation function. The problem boils \n",
    "down to a problem of stochastic state space search. Example\n",
    "are the stepwise methods proposed in linear regression analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with the output\n",
    "\n",
    "* The following code performs features selection by keeping the most correlated variables with the output. Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "    X.ts<-X[i.ts,]  \n",
    "    Y.ts<-Y[i.ts]  \n",
    "     \n",
    "    i.tr<-setdiff(1:N,i.ts)\n",
    "    X.tr<-X[i.tr,]\n",
    "    Y.tr<-Y[i.tr]\n",
    "     \n",
    "    correlation<-abs(cor(X.tr,Y.tr))\n",
    "    ranking<-sort(correlation,dec=T,index.return=T)$ix\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        DS<-cbind(X.tr[,ranking[1:nb_features],drop=F],imdb_score=Y.tr)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        Y.hat.ts<- predict(model,X.ts[,ranking[1:nb_features],drop=F])\n",
    "        \n",
    "        CV.err[nb_features,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV.err,1,mean),digits=4), \" ; std dev=\",round(apply(CV.err,1,sd),digits=4)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mRMR\n",
    "\n",
    "* The following code performs features selection by using the mRMR approach (see slides 49-52 of the course http://uv.ulb.ac.be/pluginfile.php/874401/mod_resource/content/2/fsel.pdf). Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "    X.ts<-X[i.ts,]  \n",
    "    Y.ts<-Y[i.ts]  \n",
    "     \n",
    "    i.tr<-setdiff(1:N,i.ts)\n",
    "    X.tr<-X[i.tr,]\n",
    "    Y.tr<-Y[i.tr]\n",
    "    \n",
    "    \n",
    "    correlation<-abs(cor(X.tr,Y.tr))\n",
    "    \n",
    "    selected<-c()\n",
    "    candidates<-1:n\n",
    "    \n",
    "    #mRMR ranks the variables by taking account not only the correlation with the output, but also by avoiding redudant variables\n",
    "    for (j in 1:n) {\n",
    "        redudancy.score<-numeric(length(candidates))\n",
    "        if (length(selected)>0) {\n",
    "            cor.selected.candidates<-cor(X.tr[,selected,drop=F],X.tr[,candidates,drop=F])\n",
    "            redudancy.score<-apply(cor.selected.candidates,2,mean)\n",
    "        }\n",
    "        \n",
    "        mRMR.score<-correlation[candidates]-redudancy.score\n",
    "        \n",
    "        selected_current<-candidates[which.max(mRMR.score)]\n",
    "        selected<-c(selected,selected_current)\n",
    "        candidates<-setdiff(candidates,selected_current)\n",
    "    }\n",
    "    \n",
    "    ranking<-selected\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        DS<-cbind(X.tr[,ranking[1:nb_features],drop=F],imdb_score=Y.tr)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        Y.hat.ts<- predict(model,X.ts[,ranking[1:nb_features],drop=F])\n",
    "        \n",
    "        CV.err[nb_features,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV.err,1,mean),digits=4), \" ; std dev=\",round(apply(CV.err,1,sd),digits=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "\n",
    "* The following code performs features selection by first transforming the inputs using PCA, and then keeping the most relevant principal components in the model. Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "CV.err<-matrix(0,nrow=n,ncol=10)\n",
    "\n",
    "X_pca<-data.frame(prcomp(X,retx=T)$x)\n",
    "\n",
    "for (i in 1:10) {\n",
    "    i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "    X.ts<-X_pca[i.ts,]  \n",
    "    Y.ts<-Y[i.ts]  \n",
    "     \n",
    "    i.tr<-setdiff(1:N,i.ts)\n",
    "    X.tr<-X_pca[i.tr,]\n",
    "    Y.tr<-Y[i.tr]\n",
    "     \n",
    "    for (nb_features in 1:n) {\n",
    "        DS<-cbind(X.tr[,1:nb_features,drop=F],imdb_score=Y.tr)\n",
    "        model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "        Y.hat.ts<- predict(model,X.ts[,1:nb_features,drop=F])\n",
    "        \n",
    "        CV.err[nb_features,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "    }\n",
    "}  \n",
    "\n",
    "print(paste(\"#Features: \",c(1:n),\" ; CV error=\",round(apply(CV.err,1,mean),digits=4), \" ; std dev=\",round(apply(CV.err,1,sd),digits=4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper method: Forward selection\n",
    "\n",
    "* The following code performs features selection by using a forward selection method (See slide 20 in http://uv.ulb.ac.be/pluginfile.php/874401/mod_resource/content/1/fsel.pdf). Compare the results for linear models and decision trees. What are the smallest CV errors, and how many features were needed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size.CV<-floor(N/10)\n",
    "\n",
    "selected<-NULL\n",
    "\n",
    "for (round in 1:n) { \n",
    "    candidates<-setdiff(1:n,selected)\n",
    "    \n",
    "    CV.err<-matrix(0,nrow=length(candidates),ncol=10)\n",
    "    \n",
    "    for (j in 1:length(candidates)) {\n",
    "        features_to_include<-c(selected,candidates[j])\n",
    "        \n",
    "        for (i in 1:10) {\n",
    "            i.ts<-(((i-1)*size.CV+1):(i*size.CV))  \n",
    "            X.ts<-X[i.ts,features_to_include,drop=F]  \n",
    "            Y.ts<-Y[i.ts]  \n",
    "     \n",
    "            i.tr<-setdiff(1:N,i.ts)\n",
    "            X.tr<-X[i.tr,features_to_include,drop=F]\n",
    "            Y.tr<-Y[i.tr]\n",
    "     \n",
    "            DS<-cbind(X.tr,imdb_score=Y.tr)\n",
    "            model<- lm(imdb_score~.,DS)\n",
    "        \n",
    "            Y.hat.ts<- predict(model,X.ts)\n",
    "        \n",
    "            CV.err[j,i]<-mean((Y.hat.ts-Y.ts)^2)\n",
    "        }\n",
    "    }\n",
    "    CV.err.mean<-apply(CV.err,1,mean)\n",
    "    CV.err.sd<-apply(CV.err,1,sd)\n",
    "    selected_current<-which.min(CV.err.mean)              \n",
    "    selected<-c(selected,candidates[selected_current])\n",
    "    print(paste(\"Round \",round,\" ; Selected feature: \",candidates[selected_current],\" ; CV error=\",round(CV.err.mean[selected_current],digits=4), \" ; std dev=\",round(CV.err.sd[selected_current],digits=4)))\n",
    "\n",
    "}\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further preprocessing to add categorical variables\n",
    "\n",
    "Categorical variables usually need to be transformed with 'one-hot-encoding' in order to be processed by a learning algorithm. That is, for each value of the categorical variable, a binary feature is created, which is set to one whenever that value is present. This can be done using the `dummy.data.frame` of the `dummies` package.\n",
    "\n",
    "```\n",
    "install.packages('dummies')\n",
    "library(dummies)\n",
    "```\n",
    "\n",
    "In the following, we add some categorical variables to the peprocessing dataset. The set of categorical variables is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have an overview of the their content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factor<-data[,factor_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(data_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factor[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us keep four of them: Color, language, country and content_rating, and transform them with one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_to_keep<-c(\"color\",\"language\",\"country\",\"content_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_factor_onehot <- dummy.data.frame(data_factor[,variable_to_keep], sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(data_factor_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_factor_onehot[1:2,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These could be added to the previously preprocessed dataset, and used to further improve the prediction accuracy using the feature selection/ensemble techniques seen above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed_extended<-cbind(data_preprocessed,data_factor_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(data_preprocessed_extended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using other predictive models\n",
    "\n",
    "Other models could be used, for example support vector machines, neural networks, K-nearest neighbors (using the `svm`, `nnt`or `lazy` functions from the `e1071`, `nnet` or `lazy` packages, respectively). Note that scaling the data is usually necessary when using neural networks and K-nearest neighbors approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
